{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d2465dbf-f204-4eaf-bdad-18b3d7cf359e",
   "metadata": {},
   "source": [
    "## First Load in the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0500a9f6-a8c7-4ac5-8777-3e23d752eade",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"description\":\"\\u2022\\tIdentify and fix over 400 disruptive transportation shipments per day to increase trucking customer\\u2019s revenue and Shiplify's efficiency\\u2022\\tHelped increase from a 93% success rate to 96% success rate over 3 months for the machine learning software which calculates over 300,000 shipments per day\"}\n",
      "{\"description\":\"Digital Self-Service Launch: Successfully launched over 90% Straight-Through Processing (STP) menus for self-service, integrating Chat-bot technology across Thailand, Indonesia and Singapore.Operational Efficiency: Achieved a 15% reduction in agent inquiries through increased deflection rate, contributing to improved operational efficiency.Strategic Partnerships: Drove strategic partnerships with Fintechs like Avatech.AI,  Walkme, Bancassurance fintechs.\"}\n",
      "{\"description\":\"- Prototyped AI Chatbot and Agents ingested with vector-embedded knowledge base and production feature store using Anthropic Claude and AWS Bedrock.- Built Urgently\\u2019s award winning pricing engine (https:\\/\\/tinyurl.com\\/42n7ared), reducing human intervention by 22% and achieving $1.19MM in annual savings.- Architected and deployed the company's first ML system for provider-customer matching, processing 50k requests\\/day, doubling the match rate, and delivering $2.2MM in annual savings.- Recruited and led a team of data scientists in transforming existing products related to search, pricing, forecasting, and measurement; reported directly to Chief Data Officer.\"}\n",
      "{\"description\":\"1. Research and development of algorithms for classification and grading of steel metallographic structures1) Analyzed and summarized customer demands, learned the characters and rating standards of various metallographic structures, wrote project scopes of the project statement of work, summarized the key points in metallographic standards and organized training activities.2) Trained models for classification and grading of some steel metallographic structures4) Development of the image processing algorithms for the size computation and rating of graphite.2. Defects detection of PCBAutomatically detected the bad mounted components on the PCB boards based on the algorithms combined with the object detection algorithm of deep learning and traditional image processing algorithm, greatly reduced the missing detection rate and manual review rate of the boards, met the demand of production rhythm, supported and guaranteed the project acceptance.3. Feasibility verification of bearing defect detectionResearched and trained models for the detection of bearing surface defects (including scratch, bump, step, dirt and surface lettering recognition.)4. Feasibility verification of identification of logistics itemsResearched and trained models for automatic identification of logistics items5. College cooperationGuided the student to complete the graduation thesis, including topic selection and algorithm selection.6. Automated test development Developed scripts of the web testing process based on selenium for the VE production.7. Testing programs Test tasks for the storage products such as TSM VE and BA.8. PatentsSubmitted 7 disclosures: 3 of them are Publish, 1 of them is Published.\"}\n",
      "{\"description\":\"1. Research and development of smart heating algorithm1) Analyzed and summarized the demands of heating, observed the heating phenomenon and summarized the rules in the heating process that can be used in the analysis of input data of the heating models.2) Being in charge of the data acquisition required by the project, coordinated the cooperation between the algorithm group and the on-site colleagues3) Put forward the overall solution of smart heating, and preliminarily designed the AI solutions of the whole heating process.4) Development of automatic valve regulation based on Selenium6) Developed the flow prediction (required to achieve the indoor temperature target) models based on MLP and LSTM, deployed the models into the heating process.7) Trained models of indoor average temperature prediction based on some common machine learning models9) Set up algorithm development team, recruited algorithm engineer and software engineer, assigned tasks and managed development team.10) Designed and developed an automatic training framework for the indoor average temperature prediction model.2. Research and development of algorithms for smart rangehood1) Analyzed and summarized the demands of smart rangehood2) Set up smart application development team, recruited algorithm engineer, hardware development engineer and embedded software development engineer3) Organized the activity of collecting cooking data from the customers for the recognition and analysis of lampblack4) Trained models for the smart rangehood including lampblack recognition, cookware recognition, action (causing lampblack) detection, etc.5) Designed and developed the recognition framework, including image data extraction, preprocessing and other related functions.3. Patents  Submitted more than 10 patents: 2 patents are Granted, others are in the status of Substantive Examination\"}\n",
      "{\"description\":\"Proprietary trading and software development for ML in finance and trading\"}\n",
      "{\"description\":\"Develop meaningful measurements or features of content and novelty of scientific works through the application of text mining and natural language processing (e.g., topic modeling, sentiment analysis,) techniques to a large corpus of biomedical literature. Additionally, create prediction and classification models using these validated measurements or features while working with the LISH Data Science Team to design and execute data science and AI development contests with partner research organizations.\"}\n",
      "{\"description\":\"taking part in research and development projects focusing on adapting Machine Learning technologies to real life applications. My tasks include implementing and tailoring Machine Learning algorithms to business needs. I have experience in supervised and unsupervised learning algorithm implementations.\\u25a0WebWatch Project taking part of development of application that provides web analytics services. The main focus of interest was topic-based sentiment analysis and web usage mining ( recognizing behavior patterns via link traverses utilizing LCS and segmentation)I was responsible for the design and implementation of the web crawler module and the sentiment analysis module. I implemented a Robust Risk Minimization classifier to carry out the task.\\u25a0Molecule project in cooperation with Alfred R\\u00e9nyi Insitute of Mathematics, Hungarian Academy of SciencesThe Project's objective was to synthetize new kinds of pharmaceutical substances in a combination of commonly used and accepted chemical profiles ( chemical reactivity descriptors of reagents and molecules used as training sets for predictions).My task was to design the data model and implement the machine learning algorithm proposed and formulated by Alfred R\\u00e9nyi Insitute of Mathematics\\u25a0IDS Project taking part in development of an Intrusion Detection System capable of performing real-time traffic analysis. Responsible for implementing java technology based algorithm framework.\\u25a0mDurance project with Semmelweis Universitybuilding data mining model that delivers personalized recommendation services for young individuals who are passionate about professional sport career. The application predicts the sport activity that best fits the individual's antropometric profile. \\u25a0Semmelweis UniversityMachine Learning aided blood test diagnosis for cancer detection\"}\n",
      "{\"description\":\"IFounded the North American branch of BASF\\u2019s statistics, business analytics and machine learning\\ncompetency center. Established a durable source of internal collaboration with businesses, corporate units and manufacturing facilities by generating sizable savings and\\/or EBIT:  \\n    \\u2022 The advent of complex trading algorithms operated by many market participants had made BASF\\u2019s legacy fundamentals trading strategy less successful in the most liquid precious metals markets. Therefore, developed and delivered a tailored algorithmic trading service that generated millions in revenue in the first year alone.\\n    \\u2022 Allowed manufacturing facilities to starkly reduce million-dollar losses due to production of off-spec material by building machine learning models that allow plants to react timely to deviations from normal operations\"}\n",
      "{\"description\":\"Mi occupo della gestione dell'intera server farm aziendale e come primo responsabile: della intranet e della extranet, SOA interna, Sharepoint online, bilanciamento applicativo (F5) dei servizi online, della configurazione delle strutture applicative (web app, WCF, servizi Windows), file server e dell'implementazione delle strutture server ex-novo. Sono co-responsabile dell'infrastruttura di hosting virtuale Nutanix della server farm e dell'infrastruttura di backup. Curo la progettualit\\u00e0 in cloud su Azure (DR, app, logging, Key vault, IAM, migrazioni server, front-door, monitoraggio applicativo cc. ).  Sono stato project leader per la migrazione della posta su Exchange 365 online, dell'implementazione dell'infrastruttura applicativa SOA, nella realizzazione di una struttura documentale sia su Sharepoint 2013e 2016 che su Sharepoint online, della individuazione e realizzazione della struttura server web e dati del sito istituzionale per il quale curo anche il data layer nel ruolo di database administrator. Sono il responsabile della gestione infrastrutturale per la parte WordPress e MySql e del sistema di deploy dei contenuti del sito istituzionale. Svolgo anche il ruolo di trainer per la la formazione tecnica del personale interno. Ricopro da alcuni mesi anche il ruolo di DEC. Negli ultimi due anni mi sono specializzato nelle nuove teconologie di intelligenza artificiale con corsi di specializzazione specifici. Ho conseguito un   master su AI presso Talent Garden.  Ho ricoperto il ruolo di project leader per lo sviluppo di una chatbot aziendale basata su AI generativa di cui attualmente curo gli aspetti evolutivi e di content management. Sempre in questa fase attuale mi sono specializzato nell'utilizzo di Python, PHP e Javascript. Ho da poco curato la progettazione e lo sviluppo, e  l'integrazione con l'AI di una applicazione in PHP e MySQL per la gestione della KB aziendale. Attualmente mi sto occupando del progetto di  migrazione in cloud del DevOps aziendale.\"}\n",
      "{\"description\":\"I have developed a Deep Learning algorithm for the classification of electrocardiograms.\"}\n",
      "{\"description\":\"\\u27a3 Developed Augmented Reality (AR) project with five team members. Goal: To reduce failure rate in router Customer Self Installations (CSI) saving the company $28M per year (projected).\\u27a3 Pioneered novel initiative for internal \\\"Shark Tank\\\" competition. Project: using Natural Language Processing (NLP) to enhance Business Intelligence (BI), Data Insights, Customer Experience and Brand Insights by understanding customer reviews and sentiment. Gathered information from across the organization to narrow scope and direction. \\u27a3 Cleaned up micro-services code on internal applications to make it more dynamic and easier for business users.\\u27a3 Designed 22 High Fidelity screens for an iOS application prototype using Adobe XD \\u27a3 Working with cross-functional teams and key stakeholders to bring projects closer to production.\\u27a3 Wrote Project Plan and Pitch Deck for new innovation project using brand guidelines.\\u27a3 Presented to 65+ key stakeholders and leadership ranging from Associate Directors to SVP\\u2019s.\"}\n",
      "{\"description\":\"- Demonstrated strong attention to detail by meticulously cleaning, reorganizing, and preprocessing data for a domain-specific AI project. Conducted comprehensive competitor analysis on 50+ potential competitor companies to identify market trends and inform strategic decisions. - Collaborated effectively with the team to ensure the availability of high-quality and processable data, contributing to the successful training of the AI model. The transformation of the data led to a 50% increase in outreach, significantly enhancing business outcomes and operational efficiency.\"}\n",
      "{\"description\":\"Develop and grow the IBM HW and SW business in the areas of storage systems, business automation, analytics, cloud, Watson AI.Execute the IBM strategy in co-operation with global and local stakeholders.Support TD SYNNEX partners to help them improve their skills and increase their market share.Lead the IBM unit in order to maximize the impact on the market.Re-establish and maintain a high level service of excellence with the growing TD SYNNEX partner network.\"}\n",
      "{\"description\":\"\\u2022\\tLeading a global team of 10 people across word wide IBM, supporting Europe and Middle East Africa region with HR related services, such as: employee data management, contract changes, employment certificate, leave requests, payroll related tasks, on boarding, off boarding, HR queries. \\u2022\\tWorking on different innovation and transformation projects to improve our services and employee satisfaction by using AI.\"}\n",
      "{\"description\":\"Setting up a new HR Services team in a start up company Kyndryl as part of a global project. Leading the global team of 13 HR advisors accorss EMEA, supporting 38 countries in Europe and Middle East Africa region with employee life cycle related queries and employee data management. *Taking part in innovation and transformation projects to improve our services and employee satisfaction by using AI.*Coching new team members and buliding a positive team environment.*Working on processes descriptions and shared knowledge base.*Setup SME structure and back up system to ensure a self-driven teamwork.\"}\n",
      "{\"description\":\"Co-founded an AI and data company specialising in consumer-to-consumer betting exchanges, which was profitable from month one.- Briefed team of developers to translate complex mathematics into code. - Successfully sold the business after 18 months, working with the acquirer to establish the business overseas and to earn-out.\"}\n",
      "{\"description\":\"In addition to consulting and development responsibilities, I am involved more pre-sales activities (often  related to text processing), and team coordination.\\n\\nMain tasks and responsibilities:\\n. Contributing to an anti-money laundering system by developing an information extraction process\\n. Supporting sales by development and giving demos, mainly regarding text processing (NLP) and network analysis\"}\n",
      "{\"description\":\"\\u2022  Designed & Reviewed the Architecture for the Approved Aws Services \\u2022  Automated the AWS Account Onboarding & Inflation Process which includes Account Creation, SCP Enablement, Human IAM Role Deployments, IDP setup, Logging enablement & Aggregation etc. \\u2022  Developed & Implemented Terraform Scripts to deploy Network components. \\u2022  Configured & managed centralized log collection and processing for Cloud trial Logs \\u2022  Has extensive Knowledge on AWS services Compute (EC2, ECS on Fargate, EKS, ELB), Storage (EFS, EBS, FSX) Network (VPC, Subnets, Routes,IGW, TGW, Peering, privatelink, IAM(Roles, Policies, Permission boundaries, Groups), Backup, DRS, SCP, Config, Audit Manager, Guardduty, Security Lake, Gen AI Models, etc. \\u2022   Enabled the System Manager Service to gather inventory, deploy Cloudwatch Agents to gather Memory & Disk metrics, Deploy Documents to perform any configuration changes. \\u2022  Streamlined the AWS Root Account Management Process, IAM Roles based on the domain, roles & responsibilities. \\u2022  Designed & Implemented solutions to Migrate Data\\/Applications from on premises to AWS Cloud.\"}\n",
      "{\"description\":\"I lead and consult on a wide variety of projects at Radnet. My goal is to deliver scalable, consistent solutions that intelligently leverage process and technology. Some recent projects have been focused on: \\u2022 Built business case, developed partnerships, and oversaw contract negotiations for development of custom analytical tool \\u2022 IT Service Management (ITSM)  initiative that drove a 35% increase in productivity \\u2022 Using Natural Language Processing (NLP) to categorize free text e-mail \\u2022 International Project Overseeing Enterprise Data Warehouse Architecture for a National Government Breast Screening program \\u2022 Data aggregation and reporting to meet Physician Quality Reporting System (PQRS) requirements \\u2022 Development of Medicare Merit Based Incentive Payment System (MIPS) exception workflow tool\"}\n",
      "{\"description\":\"Quadrical\\u2019s AI powered SaaS engine helps enterprises enhance the value of their data streams by identifying optimal solutions. Currently hiring AI experts and software architects and developers in Waterloo, Canada and Gurgaon, India.\"}\n",
      "{\"description\":\"I worked on federated machine learning in drug discovery.\"}\n",
      "{\"description\":\"I develop machine learning solutions on Google Cloud Platform.\"}\n",
      "{\"description\":\"I use ML to boost the performance of a trading algorithm.\"}\n",
      "{\"description\":\"I was working on various projects and pre-sales activities as an analyst, developer, and consultant, usually as part of a smaller team.\\n\\nRelated tasks and responsibilities:\\n. Implementing several machine learning based credit risk models as well as analyzing its performance\\n. Analyzing default spreading on a network built on transaction data\\n. Participating in building a toy self-driven car as an internal project (responsible for the CV part)\"}\n",
      "{\"description\":\"The direct supervisor: Director of Creative AI Division and Assistant to Chief Information Officer.\\u2022 Professional Project Coordinator of The Creative AI Camp for Incoming Society (CAICamp) between in-house and outsource teams (End to End).\\u2022 Prepare and coordinate the relevant matters with the government (End to End).\\u2022 Create the implementation plan and execute the plan of The CAICamp in Thailand and Singapore (NUS and IBM).\\u2022 Coordinate the relevant parties to design and implement the Artificial Intelligence Study Course (AI).\\u2022 Report and business communicate all relevant matters of the CAICamp and all Creative AI Knowledge Center directly to the Assistant Vice President and the Director of the Creative AI Division.\\u2022 Implement the AS-IS process report with sourcing error\\/gap of 7-11stores in Thailand and finding out the TO-BE process report of how AI and blockchain can minimize the errors and\\/or add up the values for 7-11 stores.\\u2022 Prepare the meeting minutes and all relevant documents (proposal and presentation) for the executive meeting with the CEO and the executive levels.\\u2022 Successfully handle all unexpected problems of The CAICamp in Singapore.\\u2022 Handle and manage all quotations and disbursements.\\u2022 Create and manage contents on the official online channels with the outsource team.For more info.www.cpall.co.thwww.facebook.com\\/caicampwww.caicamp.com\"}\n",
      "{\"description\":\"Performed dealer task and developed Machine Learning based quantitative investment decision support including universe selection , portfolio re-balancing, investment strategies and risk model by reportingdirectly to fund manager. Initiating on data science project for fund management and created pre-trade and post-trade interactive tableau dashboard.\"}\n",
      "{\"description\":\"Data Management, Data Mining, Big Data, ML\\/AI\"}\n",
      "{\"description\":\"Carry out R&D work of Hong Kong Science Park and develop solutions on intelligent machine, intelligent system, intelligent manufacturing using AI and related technologies including but not limited to machine vision, quality inspection, and content management, resource planning, modeling, prediction, optimization, etc.<br>Responsible for clients\\u2019 application and website system development and implementation, performapplication systems maintenance including support to end-users and troubleshooting<br>Assist in market analysis, system analysis, design, application testing and prepare relevant documentation\"}\n",
      "{\"description\":\"AI scientist and user experience lead\"}\n",
      "{\"description\":\"\\u2022\\tDemand Forecasting for propulsion engines - Manage demand forecasts and disposition actions from statistical modeling software.  Develop and maintain item-level forecast and supply plans, incorporating business intelligence and forecast information gathered from Sales, Marketing, Customers and the OEM.   Timely submittal of extended forecast data to OEM, as well as working to achieve acceptable accuracy levels for inventory.\\u2022\\tSupply Planning - Schedule and order products to arrive in advance of demand while ensuring a profitable match between supply and demand.  COGS analysis with product line management for each product line. \\u2022\\tExcess and Obsolescence Management - Periodic analysis of Excess & Obsolescence data reports.  Identify and coordinate internal and external actions to support the company\\u2019s objective.\\u2022\\tAnalysis and Reporting - Periodic performance through service level, forecast accuracy, reporting to include root-cause and corrective action plans for products and\\/or product lines performing below target.  Maintain continuous improvement plans to include strategic actions to enhance inventory productivity while maintaining target product availability.  Review historical sales trends, research demand drivers, prepare forecast data, develop statistical forecast models and evaluate forecast results.  Prepare and present reports and analysis advising stakeholders of variances between existing forecasts, plans and actuals.\\u2022\\tMilestones - O-Ring and blade project for process mapping, supplier\\/customer input\\/output process.\\tStress test beta projects in Excel tables, Spotfire Reports, External Portals, SPM, and SAP to verify new review reasons, discuss and test critical filter options and other queue filters.  HyperCare workshop with Capgemini team for fine tuning results for new SPM inventory system.  Meet contract commitment requirement for product lines.  Identify pull-in and push out POs through data analysis of various systems and teams.\"}\n",
      "{\"description\":\"We built an AI-powered Smartphone app for Art-enthusiasts, in partnership with local galleries.\"}\n",
      "{\"description\":\"Developing human-machine interfaces, semi- and unsupervised recognition algorithms at Verizon.Major projects:Application of CycGANEvaluating different boundary constraints (based on Gradient Penalty) for WGANImproving on performance for Pose estimationTraining facial landmark localization algorithmsAge, gender, emotion detectionBenchmarking Domain Adversarial Neural Networks (DANN)Benchmarking vehicle and pedestrian detection from surveillance cameras with YOLO\"}\n",
      "{\"description\":\"- Responsible for developing solutions suitable for real-time processing environment and make accurate decisions.- Developing many ML models include Sentiment Analysis, Text Category Detection, Terrorist Detection, Emotion Detection, and Names Gender Detection model, depending mainly on FastText, Conditional Random Field (CRF), and Support Vector Machine (SVM) using Python..- Implementing an intensive Pre-processing pipeline since the target language is non-standard Arabic, instead, it is the Syrian dialect.- Developing and maintaining back end services using Django.\"}\n",
      "{\"description\":\"* Building supervised and unsupervised Machine learning Models * Exploratory Data Analysis on Retail , superstore Find businesssolutions to make more profit*Exploratory Data Analysis on Global Terrorism , find out the hot zone of terrorism. *Exploratory Data Analysis on Indian Premier League , find out the most successful teams, players and factors -contributing win or loss of a team. *Create a hybrid model for stock price\\/performance prediction usingnumerical analysis of historical stock prices, and sentimental analysis of news headlines *Create a storyboard showing spread of Covid-19 cases in Asia,Identify interesting patterns and possible reasons helping Covid-19spread\"}\n",
      "{\"description\":\"Writing full Arabic Accurate blogs in artificial intelligence , Machine learning , Deep Learning and Natural language processing Trying to show artificial intelligence to the world\"}\n",
      "{\"description\":\"Responsible for managing and executing Amazon's pricing strategy for global retail business units. \\n\\nMy teams are responsible for ensuring that pricing at Amazon remains competitive. I lead an organization of 650+ team members spread across multiple locations, comprising of technology, technology operations, business operations and quality teams. The technology problems span across the areas of distributed systems, scalable web crawling, statistical algorithms, machine learning and data mining.\"}\n",
      "{\"description\":\"\\u25c6 Pilotage du programme de social selling avec les \\u00e9quipes commerciales \\u25c6 Copilotage du projet de mise en conformit\\u00e9 GDPR\\/RGPD de 25 sites web, de leurs bases de donn\\u00e9es et des campagnes Emailing\\/Infolettre dans 16 pays \\u25c6 Formation en fran\\u00e7ais et en anglais \\u00e0 l\\u2019utilisation de la solution Emailing\\/Infolettre Activetrail, de la solution de montage vid\\u00e9o en ligne 2Emotion et de l\\u2019outil de social selling LinkedIn Sales Navigator \\u25c6 Garant du respect des bonnes pratiques des campagnes emailing et de la charte graphique des vid\\u00e9os de programmes immobiliers pour le site www.bnppre.fr \\u25c6 En charge de faire valider au d\\u00e9partement Juridique tout projet web du point de vue l\\u00e9gal \\u25c6 Captation, montage et sous-titrage de vid\\u00e9os sous Adobe Premiere Pro et 2Emotion \\u25c6 D\\u00e9ploiement d'un r\\u00e9seau social interne et formation des employ\\u00e9s \\u00e0 son utilisation Principales r\\u00e9alisations : \\u279c Coordination des 16 pays pour la mise \\u00e0 jour de leur site et synchronisation de 9 pays pour l'envoi de campagnes emailing en vue de la mise en conformit\\u00e9 GDPR\\/RGPD \\u279c Pilotage du d\\u00e9ploiement de la strat\\u00e9gie et des outils de gouvernance r\\u00e9seaux sociaux \\u00e0 l'international dans 7 pays \\u279c Cr\\u00e9ation de guides d\\u2019utilisation et de bonnes pratiques des r\\u00e9seaux sociaux, de la solution Emailing\\/Infolettre Activetrail, de la solution de montage vid\\u00e9o en ligne 2Emotion et de la solution de Social Selling LinkedIn Sales Navigator en fran\\u00e7ais et en anglais \\u00e0 destination des employ\\u00e9s de la soci\\u00e9t\\u00e9\"}\n",
      "{\"description\":\"Business Developer as part of SAP Innovation Center Network (ICN) Machine Learning team, responsible for Key Enterprise Accounts across various industry sectors in Northeast and South market units in US.\"}\n",
      "{\"description\":\"Work stream leadership for transition (ML) activities. Work leader for access management transformative projects.\"}\n",
      "{\"description\":\"Propose solutions to meet clients\\u2019 needs and serve as the industry expert to prospective clients in the fields of Robotics, Digital Process Automation, CRM, and AI.\\n\\nAssist in the production of RFP\\u2019s and other proposals to clients.\\n\\nDeliver POCs and custom demonstrations to meet the scope and functionality to ensure that all success criteria are delivered and product differentiators are included.\\n\\nCollaborate with product managers, software developers, analysts, business officers, and other groups ensuring the successful execution of the sales strategy.\\n\\nProvide thought leadership in technology across separate industries.\"}\n",
      "{\"description\":\"Worked on predictive modelling using statistical techniques and machine learning tools.\"}\n",
      "{\"description\":\"\\u2022 Conduct exploratory data analysis (EDA) and design advanced feature engineering techniques for ambulatory physiological signals, successfully identifying unique stress biomarkers to enhance the precision of stress detection models. \\u2022 Develop and optimize machine learning pipelines, integrating state-of-the-art time-series analysis, robust feature selection methods, and effective upsampling strategies, resulting in improved model performance, reliability and generalizability. \\u2022 Demonstrate problem-solving skills by addressing challenges in real-world physiological data, such as missing data and noise, ensuring high-quality preprocessing and analysis. \\u2022 Document workflows and results to support reproducibility and facilitate knowledge transfer across teams.\"}\n",
      "{\"description\":\"Product Owner of Photovoltaic Products Key Responsibilities: \\u2022 Communication with customers, development teams and business partners on daily basis \\u2022 Participation in product design process \\u2022 Plan and prioritize product features, backlogs \\u2022 Acceptance testing of new features \\u2022 Defining neural network research areas \\u2022 Onsite support for customers in Asia and Europe \\u2022 Incident management \\u2022 Monitoring of development progress \\u2022 Reporting for upper management\"}\n",
      "{\"description\":\"Projetei e implementei um m\\u00e9todo de deep learning que combina representa\\u00e7\\u00f5es visuais e sem\\u00e2nticas extraidas atrav\\u00e9s de redes CNN e informa\\u00e7\\u00f5es categ\\u00f3ricas textuais para melhorar tarefas de classifica\\u00e7\\u00e3o. Utilizando python e tensorflow para criar e avaliar os modelos.\"}\n",
      "{\"description\":\"ChatGPTAs a director at an educational academy, I led the development and implementation of innovative educational programs utilizing digital technology in alignment with quality educational standards. I managed the organizational structure and provided guidance to educators to ensure a comprehensive and productive learning experience for students. Through collaboration with the administrative team, we successfully achieved our objectives with excellence, enhancing the quality of education through information technology and providing a learning environment that stimulates students' learning and personal growth.\"}\n",
      "{\"description\":\"Capgemini acquired igate Global Solutions Limited , in capgemini i have worked in two projects initially i started with SQL and Unix where i have given basic work like DML statements, job monitoring, uploading files in production later year in 2015 i joined talend Team in IGATE where i started working with chespeake project which has various existing ETL flow and we need to do enhancement of those ETL based on defects after production deployment in Later stage another version of chespeake came into picture where we need to start ETL from scratch i was only ETL resource in chespeake where i designed ETL flow to deployed and and currently resolving defects and add on requirements on the ETL At the same time i m working on Fin source project whose approx more than 5 ETL i have only designed and implemented of which two are already in Production and with 0 defects it , these jobs are scheduled via autosys , so i have basic knowledge of Autosys , where we create enviornment file, jil (job information language) and shell scripts for archive and back up.\"}\n",
      "{\"description\":\"Cientra is a global Engineering Design & Services company, rapidly growing with a vision to remain the preferred vendor in the industry. Has multiple turnkey engagements with large multinational corporations from industries such as Semiconductors, Telecommunications, Automotive & Aerospace. With itu2019s strong technology DNA, Cientra is transforming the way companies do business. Engaging with customers as partners and helping them to gain competitive advantage in the market place. Cientra along with its rich portfolio of next generation IP cores, offers best in class services in the following Engineering functions: 1) Embedded SOC - Design - Verification - Synthesis - Emulation - Physical Design - Analog Layout 2) Automotive - Algorithm - Modeling & Simulation - Hardware\\/Software Compliance 3) Artificial Intelligence - Machine Learning - BOTS - Voice - Image Recognition 4) IoT - Consulting - ISV\\/Platform - CSV\\/MVNO\\/MNO - OEMs\\/Device 5) Aerospace - DO 178 B\\/C - DO 254 - ARP 4754 - Software - Firmware - Application 6) Telecom - Software Development & Testing - 3GPP RAN - Protocol Stack - Cellular IoT - 5G Enhancements Website http:\\/\\/www.cientra.com\"}\n",
      "{\"description\":\". Engineering leadership of 175 engineer specialized on Product & System + Electrical, Electronics and Semiconductors for automotive and rail industry (+17% growth in 2023). Tehnical lead in System development. Actor of the the changement of organization from Altran to Capgemini (Tools, process ...). Responsible of the performance of his engineers unit (Cost, Skills, Carreer, Business, world communoty, team spirit...). Member of the Auto and Rail Management Committee\"}\n",
      "{\"description\":\"My Key Responsibilities:Lead the design and delivery of enterprise cloud solutions, aligning with client business goals and regulatory requirementsDefine cloud adoption strategies, migration blueprints, and modernization roadmapsArchitect cloud infrastructure and services that scale securely and cost-effectivelyPartner with internal and client-side DevOps, Security, and Data teams to implement cloud best practicesConduct architectural reviews, risk assessments, and readiness evaluations for large-scale migrationsDeliver executive-level presentations, architecture documentation, and technical whitepapersServe as technical lead and mentor, shaping internal knowledge frameworks and architecture standardsConsulting & Leadership Skills:Proven leadership in client-facing consulting environmentsAbility to translate complex technical topics into clear business value propositionsStrong written and verbal communication skills, including executive briefing deliveryEntrepreneurial mindset with a passion for innovation, mentorship, and cloud excellenceAlso experience with Artificial Intelligence & AutomationAI Integration in Cloud WorkflowsMachine Learning Deployment on AWS (SageMaker, Lambda)AI-based Automation for IT Operations (AIOps)Data Pipeline Design for ML Workloads (Glue, Data Factory)\"}\n",
      "{\"description\":\"Lead Recruitment Process Outsourcing (RPO) Design Team, creating innovative RPO solutions and transformational initiatives for Fortune 500 organizations, saving millions of dollars and providing white-glove candidate experience*\\tDesigned RPO programs in first year with more than $200M of revenue in retail, healthcare, industrial, financial and technology verticals*\\tSpearheaded total design overhaul from traditional recruitment approach to a heavily automated, tech-driven methodology, saving clients on average $2M*\\tConceived and developed $7M RPO for major healthcare org, resulting in 50% reduction in recruitment FTE and 40% reduction in budget, leveraging AI chatbot automation, asynchronous video and pre-hire virtual simulation technology\"}\n",
      "{\"description\":\"Aligned people, processes and technology via talent identification and selection to support transformational human capital goals of this $4B global enterprise. Led(1) Global Delivery Leader (5) Regional Delivery Managers and a global team of (59) Talent Acquisition team members supporting 55 countries. -\\tManaged global stakeholder expectations of Talent Acquisition supporting corporate initiatives in 55 countries, 300+ global locations and 180 (Quick Response Centers) QRC\\u2019s in support of 3 Operational Division supporting Fluid Motion Solutions. Reporting chain to CHRO -\\tStrategically aligned Talent Acquisition Delivery with Senior Leaders (globally) to support the achievement of corporate plans while streamlining and simplifying processes to accelerate delivery. -\\tCollaborated with Corporate HR Operations and Project Teams in support of the redesign, evaluation and implementation of new process diagrams, talent mapping\\/process charting, assessment testing and functional ATS upgrades to evaluate and score talent through various social channels for talent attraction. \\u2022\\tCollaborated with Global RPO to deliver 3100+ hires in 2019 o\\tDecreased time to fill (TTF) globally by 18% \\u2022\\tRe-designed requisition \\u201ckick-off\\u201d process to include multi-language\\/multi-hire requisition template and job adverts to increase talent attraction \\u2022\\tCreated requisition aging improvement process resulting in decrease in positions 90+ days old from 23% to 5% globally \\u2022\\tImplemented Cognitive and AI tools (Watson Recruiter\\/Watson Candidate Assist) and integrated into Application Tracking Systems (ATS) \\u2022\\tLed investigation and recommendations for 1st Global RFI\\/RFP identifying possible Master Solutions Provider\\/Vendor Management Solutions (MSP\\/VMS) providers to increase scalability\\/alignment for accelerated talent delivery while decreasing administrative operational burden on global HR infrastructure o\\tReduced number of agencies globally from 200+ to under 20 (tiered)\"}\n",
      "{\"description\":\"Responsible for designing data collection workflow and training machine learning model on AI-based gait analysis for patients with knee osteoarthritis\\n\\nPitching CLAIRE's technology and business idea in startup competitions to gain recognition and raise fund for operation\"}\n",
      "{\"description\":\"I am doing research on AI-based MRI analysis for treatment decision support in patients with chronic degenerative low back pain. This is done at the orthopedic surgery department of the RadboudUMC and Sint Maartenskliniek, together with the Diagnostic Imaging Analysis Group.\"}\n",
      "{\"description\":\"Sales Manager with responsibility for all of the strategic outsourcer accounts (27).  Included EDS, CSC, Cap Gemini, Capita, IBM, SEMA, Vertex.\"}\n",
      "{\"description\":\"Built a multiclass CNN (keras) based tax document classifier with an 87% overall accuracy.Utilized image augmentation techniques and hyperparameter tuning for robust performanceImproved web service response time by 300% through efficient data packaging on C# clientDeveloped a simple Flask server to test data integrity and cross-platform data preprocessing techniquesImplemented an OCR based tax document data extraction framework in python using Azure Computer VisionReduced yearly effort by 42000 man-hours, and cut yearly costs by $770,000 while eliminating human errorIntegrated Selenium tests in Azure CI\\/CD Pipeline and published screen recording of the build agent\"}\n",
      "{\"description\":\"Built a causal inference pipeline to forecast blood glucose responses to intervention shifts in diabetic patients.\"}\n",
      "{\"description\":\"Thomson Reuters Labs ML infra\"}\n",
      "{\"description\":\"AI drug discovery, ML for healthcare, digital solutions\"}\n",
      "{\"description\":\"The research conducted examined several numerical methods for solving matrix eigenvalue problems, efficient eigensolvers and their variants: Power Iteration, Inverse Iteration, QR Algorithm, concerning techniques as iteration method, inverse iteration, shifted inverse iteration method, Gram-Schmidt process, Householder transformations, and shifted QR decomposition. We discuss the normalization\\u2019s necessity and conditional convergence property for Power Iteration Method and compare various eigensolvers\\u2019 performance. We computationally experiment on the PageRank Algorithm and its variants. Additionally, this program explored of a variety of interdisciplinary research topics utilizing large-scale linear algebra, model reduction, randomized algorithms, and deep learning. Investigating the theoretical underpinnings of efficient eigensolvers in applied and computational mathematics and working collaboratively to develop open-source software tools.\"}\n",
      "{\"description\":\"Currently working as Process Lead with Capgemini Business Services India Ltd , Bangalore from April, 2014 to till date. ( Working with North America General Accounting Team ). SAP FICO end user experience : Journal Entries Creation of Internal Orders, Settlement and Asset creation Cost Allocation, Assessment and Distribution Cost Center Reporting Depreciation Run R100\\/R101 Reporting Master Data Maintenance GRIR clearing BPC Reporting AR\\/AP\\/FA Subledger Reconciliation\"}\n",
      "{\"description\":\"Carried out Testing of Large A.C and D.C machines like Induction motors, Alternators and transformers etc. Worked on a project 'Torque Speed Characteristic Measurement by Torque Transducer' to plot the characteristic curves and measure Torque and speed of induction motors. Selected Contribution: Demonstrated proven abilities in a wide range of technical skills. Quickly moved to handle greater responsibilities including report creation.\"}\n",
      "{\"description\":\"Thermo Fisher Scientific Inc. is an American supplier of analytical instruments, life sciences solutions, specialty diagnostics, laboratory, pharmaceutical and biotechnology services. As Business Analyst and Salesforce CRM Analyst, I drove commercial process improvements and expand Salesforce CRM functionalities cross the business.  \\u25fc\\ufe0f Led project to replace outdated, manual demo hardware tracking process with automated, efficient alternative, providing accurate, real-time insights, fostering a culture of self-sufficiency, and winning \\u2018Art of the Possible\\u2019 Innovation Award.\\u25fc\\ufe0f Delivered 10+ CRM projects including investigation, definition, requirements gathering, documentation, design, risk management, back-end setup and customised configuration. \\u25fc\\ufe0f Defined, documented and shared 8 new processes for the team to aggressive timescales before and throughout a global pandemic. \\u25fc\\ufe0f Introduced Marketing AI review processes to optimise Return on Investment (ROI) for marketing campaigns, contributing to overall business success.\\u25fc\\ufe0f Championed diversity and inclusion as a proactive Member of the African Heritage Employee Resources Committee and Journal Committee Leader.\"}\n",
      "{\"description\":\"\\u2022\\tSupported the set-up of the Skills Funding Agency (SFA) Course Directory Provider Portal project. \\u2022\\tSupported with creation and implementation of training guides. \\u2022\\tFacilitated users with Portal access, the RAG rating and the CSV upload process. \\u2022\\tSupported customers with data quality compliance. \\u2022\\tPrepared and analysed a range of reports from Salesforce database in Excel.\"}\n",
      "{\"description\":\"As Chief Architect, I lead the function that helps the business through the technical and security decisions faced by the Press around the globe. As Director of Projects office, I lead the department of project and programme managers for global strategic and technology projects. - I established the cyber security practice at the Press, managing the group of Enterprise Security Architects and arranging the setup of the security operations centre. My group has delivered a cyber security policy framework with individual standards on topics including website security, password policy, incident response and supplier security. We also manage the cyber security risk register and risk mitigation actions. - By providing the Global Technology Roadmap, my team holds the picture of how the Press's systems all interact today and provide the technical strategic direction for the future based on a TOGAF approach. - I manage technical governance over all change programmes. - I work with audit and compliance on IT assurance. - I'm Design Authority for the global roll out of SAP which has successfully gone from initial design to in-operation in multiple global locations. - I am also leading initiatives in Data Science, Artificial Intelligence and Machine Learning.\"}\n",
      "{\"description\":\"- Reported to the VP Engineering (exec level and first Algolia employee)\\n- First Program Manager at Algolia, supported successfully Engineering, Product, Data, AI teams\\n\\n- Engineering: setup a culture of continuous learning through numerous initiatives: coaching, mentoring, voyagers, lunch&learn, manager codev sessions, Process Communication Model trainings, close collaboration with Engineering Managers\\n- R&D operations: setup OKRs, quarterly plannings, reorganization as squads and platforms, product manager codev sessions, R&D All Hands, close collaboration with Product Managers\\n- Data: setup Agile methodology including User Story Mapping for quarterly plannings, product adoption data framework, Product Qualified Leads, program managed data architecture and governance evolution, hired and onboarded the first Product Data Analyst, close collaboration with Data, Data ingestion, Product, Biz Ops, Growth teams\\n- AI: integrated the AI team to the R&D team, post-M&A\"}\n",
      "{\"description\":\"Working in the Law School, comprising of academic (LLB\\/LLM) and professional (GDL\\/BTC\\/LPC\\/STC) programmes, I teach and support students on undergraduate and postgraduate Law programmes.  I also engage in research and scholarly activities.\"}\n",
      "{\"description\":\"Conducting research and advising companies and non-profits on realizing the potential of AI while governing Transformative Artificial Intelligence to address associated risks. Also working on biosecurity interventions for worst-case pandemics.Consulting and advising on Strategy\\/Theory of Change, Operational Excellence, Stakeholder Management, Risk Management, and more.\"}\n",
      "{\"description\":\"\\u2022\\tAdvising on M&A, transformation strategy for global scale, operational efficiencies, turnarounds, crisis management and recovery for CX, BPO, Technology, Engineering, Travel and Healthcare services companies. \\u2022\\tConsulting on customer experience and digital transformation (AI\\/ML, RPA, IoT); right-shoring of omnichannel BPO, ITO and contact center services; supply chain re-engineering; sourcing strategy development; Identification and selection of 'Right' geography, platform and provider, etc.\"}\n",
      "{\"description\":\"T\\u00fcm tedarik zinciri, D\\u0131\\u015f Ticaret, Nakliye, depolama, Envanter Y\\u00f6netimi, Sipari\\u015f Kar\\u015f\\u0131lama ve M\\u00fc\\u015fteri Hizmetlerinin y\\u00f6netimi, geli\\u015ftirilmesi.Hayvan yemi \\u00fcretiminde kullan\\u0131lan mevcut baz\\u0131 hammaddelerin sat\\u0131n al\\u0131nd\\u0131\\u011f\\u0131 andan itibaren ithalat\\u0131n\\u0131n ve fabrika deposuna transferinin yap\\u0131lmas\\u0131, taleplere g\\u00f6re m\\u00fc\\u015fterilere temini, planlanmas\\u0131, nakliye ayarlama ve planlama.- CBOT Fiyatland\\u0131rmas\\u0131 ( Fasulye ve Soya K\\u00fcspesi)- \\u0130rsaliyelerin kontrol edilmesi ve haz\\u0131rlanmas\\u0131.- G\\u00fcnl\\u00fck sevkiyata ba\\u011fl\\u0131 Sat\\u0131\\u015f Faturalar\\u0131n\\u0131 kesmek.- Al\\u0131\\u015f Faturalar\\u0131 takibi ve kontroll\\u00fc i\\u015flenmesi.- En iyi hizmeti sunmak i\\u00e7in depo ve nakliye \\u015firketleri aras\\u0131nda koordinasyon.- Sat\\u0131m s\\u00f6zle\\u015fmelerini zaman\\u0131nda y\\u00fcr\\u00fctmek ve haz\\u0131rlamak.- S\\u00fcrekli ileti\\u015fim halinde bulunarak sipari\\u015flerin, stok miktar\\u0131n\\u0131n, sevkiyat\\u0131n planlanmas\\u0131 ve takibi.- Sipari\\u015fin t\\u00fcketiciye zaman\\u0131nda teslim edilmesini ve m\\u00fc\\u015fterilerden gelen teslimat taleplerinin yerine getirilmesinin planlanmas\\u0131.- Ta\\u015f\\u0131ma operasyonlar\\u0131n\\u0131n g\\u00fcnl\\u00fck, haftal\\u0131k raporlanmas\\u0131.- Sorunsuz sevkiyat s\\u00fcreci sa\\u011flamak amac\\u0131yla nakliye \\u015firketleri, m\\u00fc\\u015fteriler, depolar, liman yetkilileri ile ileti\\u015fimi s\\u00fcrd\\u00fcrmek.-D\\u00f6kme y\\u00fck gemilerinin atanmas\\u0131 ger\\u00e7ekle\\u015ftikten sonra sertifika takibi, geminin T\\u00fcrkiye'ye ula\\u015fma s\\u00fcreci, acentelerle ve g\\u00fcmr\\u00fck\\u00e7\\u00fclerle g\\u00f6r\\u00fc\\u015fme, liman depolarla, antrepolar ile g\\u00f6r\\u00fc\\u015fme s\\u00fcreci, takibi.\"}\n",
      "{\"description\":\"During my research internship, I engineered and executed a comprehensive testing protocol for pre-trained machine learning pipelines, resulting in a 15% increase in accuracy on the test dataset. Additionally, I authored detailed documentation on Automated Machine Learning processes and best practices\"}\n",
      "{\"description\":\"Au sein du service emploi de la Mission Locale. Personne ressource jeunes en situation de handicap aupr\\u00e8s des conseillers Mission Locale. Cr\\u00e9ation et animations d'ateliers sp\\u00e9cifiques, d\\u00e9couverte du milieu prot\\u00e9g\\u00e9 (ESAT, ESAT hors mur, entreprises adapt\\u00e9es) . Animation de l'atelier recherche d'emploi en partenariat avec coll\\u00e8gues Mission Locale (2 semaines chaque mois). D\\u00e9veloppement du r\\u00e9seau de parrainage ML : prospection en entreprises. Pr\\u00e9paration et accompagnement des jeunes aux forums recrutement...\"}\n",
      "{\"description\":\"\\u2022 Strong decision maker with ability to understand project objectives, scope, and deliverables, and adapt to changes, resulting in the implementation of company inventory data automation projects across 4 regions and 2 product segments. \\u2022 Cross functional coordinator with expertise in developing machine learning models using Python resulting in the timely completion of over 3+ interdisciplinary projects in manufacturing, finance, and supply chain domains. \\u2022 Expert problem solver skilled in using MS Office and data visualization tools including Power BI, as evidenced by the development of tools and metrics to proactively identify and fix issues and misalignments with data-oriented projects among teams across the world.\"}\n",
      "{\"description\":\"I am glad to share that I'm doing a research stay abroad at CREATIS, INSA Lyon! I will stay abroad for 6 months as a part of my doctoral degree and collaborate with this talented research group.During my stay, I will work on generation of realistic synthetic ultrasound data for the purpose of  training and validating segmentation and motion tracking algorithms for diagnostic support. Transesophageal data will be generated by adopting a simulation pipeline developed within CREATIS, INSA, Lyon. Synthetic data will also be used to train state-of-the-art machine learning-based methods for segmentation and motion tracking.\"}\n",
      "{\"description\":\"Interset was an In-Q-Tel venture-backed software company providing a Security Analytics (UEBA) platform that utilizes Unsupervised Machine Learning to detect and surface Insider Threats. I started with the company as an early-stage startup and it was acquired by Micro Focus in 2019. \\u2022\\tResponsible for developing the market for this emerging technology with some of the largest enterprise accounts in region \\u2022\\tTop regional producer in 2016, 2017, 2018 & 2019 (Notable wins- AT&T, Bell Canada, Motorola and DoD. & .gov \\u2022\\tCompany was acquired in 2019 by Micro Focus and I became a SME supporting the Global Sales and SE team, along with their Channel sellers, with their customers' Insider Risk projects.\"}\n",
      "{\"description\":\"As the Head of the Agile Coaching Practice I am responsible for coaching a staff of great agile coaches and enabling the growth of agility for the organization.Started and continue to have Scrum Master mentoring circles. Since then a Scrum Master has been promoted to my team as an Agile Coach.With the support and championing by senior leadership, I initiated and continue to expand CBREs Communities of Practice. We have Scrum CoP, Product Management CoP, Machine Learning CoP, and Leadership CoP.Co-organizer for the Product Management CoP. As a co-organizer I bring in guest speakers, occasionally present, and help connect people with each other to share ideas. Training programs, the ask from the community was short micro training classes. The Agile Coaches develop (and continue to refine) a number of classes that supports both remote attendance and face-to-face. Remote classes leverages tools such as Weave. Both classes incorporate training from the back-of-the-room techniques to create a high impact learning environment.\"}\n",
      "{\"description\":\"2022 Top Sub Account Team Winner2021 Circle of Excellence, Gold Club Winner2019 - 2023 Champion - Multiple internal committeesAll Microsoft Solution Suites: ERP, CRM, Azure Cloud, Data, AI, Security, Modern Workplace etc\"}\n",
      "{\"description\":\"A) Based on stakeholders' business requirements, developed and deployed machine learning applications\\/products to increase the rate, efficiency, and safety of oil & gas drilling, completions, and production as well as to serve other central departments (i.e., marketing, accounting, HR); and \\nB) Discovering predictive and prescriptive trends and insights based on the advanced machine learning modeling of oil & gas data.\"}\n",
      "{\"description\":\"A) Based on stakeholders' business requirements, develop and deploy machine learning applications\\/products to increase the rate, efficiency, and safety of oil & gas drilling, completions, and production as well as to serve other central departments (i.e., marketing, accounting, HR); and\\nB) Discovering predictive and prescriptive trends and insights based on the advanced machine learning modeling of oil & gas data.\"}\n",
      "{\"description\":\"Developed automatic solutions for inventory control problems.  \\n\\nDesigned machine learning for inventory control.\\n\\nUse and maintain Redshift and MySQL databases for backend software usage. \\n\\nDesigned metrics reporting for North America.\\n\\nDesigned internally used website for metrics reporting.\"}\n",
      "{\"description\":\"MEET ME AT THE CROSSROADS OF PLANT PASSION! I love the horticulture industry and I've spent more than 30 years discovering its nooks and crannies. My extensive expertise, experience, and enthusiasm can be put to use in a variety of ways to help your botanical practice bloom, be it personal or professional. EARNINGS: My specialty is hybridizing science-based horticultural know-how with botanical business & marketing savvy to provide deep insight to business & brand coaching clients. Through my Plant For Profits program, I provide vision, focus, and growth opportunities & strategy guidance for plantrepreneurs + career transformers: growers, plant shop owners, garden designers, landscape architects, interiorscapers and plant stylists, arborists, + horticultural product developers. EDUCATION: As a UCLAx Horticulture Instructor and plant book author, I develop & teach science-based courses in horticulture, botany, and horticulture business; targeted to industry members, career tranformers, and entrepreneurs. Look for new courses soon. As a degreed and ASHS Certified Professional Horticulturist, I provide horticultural consulting for commercial or residential properties and projects; Greenhouse growers, breeders, landscape architects, design & build firms, landscape maintenance companies, nurseries, garden centers, and companies that create horticultural products. EXPRESSION:  I am a confident and empowering speaker ready to energize your industry conference, event, or staff training. I provide Keynotes & Workshops on horticultural, green industry business, and marketing topics for the industry; as well horticultural programs related to my books for consumer-facing events, and provide expert quotes\\/interviews for the media. As a botanical artist I express plant passion through art and illustration, which you can find at my website. EXPLORATION: I love botanizing and plant-focused travel, so stay tuned for upcoming botanizing travel experiences!\"}\n",
      "{\"description\":\"- Python APIs in Flask- MSSQL- Machine learning classification and clustering\"}\n",
      "{\"description\":\"\\u261b  Artificial Intelligence \\n\\u261b  Principles of Machine Learning\\n\\u261b  Database Systems \\n\\u261b  Systems Analysis & Design\\n\\u261b  Applied Statistics\\n\\u261b  Introduction to Programming\"}\n",
      "{\"description\":\"Wing had good reputation and did well in Hardware,Software,AI\\/Big Data\\/Block Chain\\/Cloud\\/Chips\\/IoT and all kinds of new technology related areas.\"}\n",
      "{\"description\":\"Job Responsibilities:\\uf0b7 Installation & termination of DB's, Panels, Lightning Arrester & Earthing.\\uf0b7 Installation & Commissioning structural cabling, cable laying and its supports and trenching.\\uf0b7 Electrical Equipment\\u2019s used in power plant like HT\\/LT motors (Induction and synchronous), HT\\/LT Transformers, wide range of Switchgears, Rotary and static UPS, Battery chargers, etc.\\uf0b7 Having experience of close & open the earthing Switch of various bays.\\uf0b7 Preparing & Maintenance the documents, Records and Reports of projects.\"}\n",
      "{\"description\":\"Enhanced fast fashion profitability by 17% through the development and successful A\\/B testing of prototype Pricing and Relevancy Engines using cutting-edge machine learning. Implemented a feature analysis algorithm, reducing human intervention and minimizing dimensionality in AI algorithm feature selection, resulting in improved efficiency and performance. [Article Link below]\"}\n",
      "{\"description\":\"Projet MSP pour EDF\\/Gaz de France pour le compte de Capgemini Gestion du projet (mixte TMA\\/AT de 2 personnes, CA 25 K\\u20ac) de scellement et contr\\u00f4le d\\u2019int\\u00e9grit\\u00e9 des lots de paiement ASCII et EBCDIC avec reprise et maintien des comp\\u00e9tences, diagnostics, corrections\"}\n",
      "{\"description\":\"- Conduite d'audit conformit\\u00e9 RGPD en France et au Maroc (en tant que Responsable de traitement et Sous-traitant) - Contribution au besoin des op\\u00e9rationnels sur les probl\\u00e9matiques data - Recommandation sur la n\\u00e9gociation de contrats - Pr\\u00e9parer des supports de communication, de formation, de sensibilisation\"}\n",
      "{\"description\":\"Group InnovationArchitecture & AI-Technology\"}\n",
      "{\"description\":\"Transformed the Business Development function for APAC by: integrating two separate departments; hiring a new senior management team; and redesigning the operating model for the function Launched growth programs for multiple new countries; financial services; subsea; genomics & healthcare AI Co-leads WeAreEquinix for APAC: Equinix\\u2019s program for Diversity, Inclusion & Belonging Doubled APAC internet exchange traffic over three years \\u2013 with Singapore becoming the 4th largest IX globally The team hosts >20 events annually, inc. the Asia Peering Forum (>140 customers) & the India Peering Forum Nominated to the Presidents\\u2019 Club 2023 (for sales excellence), & Archimedes (Equinix\\u2019s leadership incubator)\"}\n",
      "{\"description\":\"ThoughtSpot is a search & AI-driven analytics platform designed for the business user. Not only was this meant for ease of use for line of business employees that are in constant need of data to make better decisions, but it also allows Business Intelligence and IT teams to focus on important data initiatives. BI teams no longer need to have a backlog of ad-hoc reporting requests, and LOB teams can ask questions  of several different data sets that will help them understand their business in a matter of minutes. I'm focused on 30 key accounts in the TOLA region, spreading awareness, generating pipeline, and bringing in revenue as we continue to grow at an exponential rate, 195% YTD '19.\"}\n",
      "{\"description\":\"I managed the Microsoft data platform and hybrid cloud sales business for enterprise customers in the South Central Region for six years.  In this role, I led a team of sales executives and technical pre-sales specialists\\/architects with over $100M quota.  We worked with customers and partners (ISV's, Global Alliance Partners, and National SI's) to drive on premise, hybrid, and\\/or cloud solution sales including Big Data (HADOOP), IAAS, PAAS, and cloud based advanced analytics solutions including machine learning, data warehousing services, and cloud based analytics solutions including PowerBI. We leveraged overlay technical sales staff including data scientists.  Our key competitors included Amazon Web Services, IBM Soft Layer, Rackspace, Teradata, SAP, Oracle, Salesforce.com, and many others. *  Our region exceeded quota four out of six years and our team won many large competitive takeout and \\\"Marquee\\\" deals consistently driving ~ 10% year over year revenue growth in the regions SQL Server business.  Our team finished twice in Top 2 of the 12 US regions on annual quota attainment in region rankings.*  We won many different large Azure workload deals, region was #1 US enterprise in FY 16 on Azure usage, and I led the ISV Co-Sell initiative for region finishing as one of two US enterprise sales regions that exceeded the very high win target set by our US leadership team.*  My team drove over 25 HP & Dell Massively Parallel Processing (MPP) Data Warehouse appliance unit wins and the initial marquee customer references which were used by Microsoft scale out and grow global MPP Data Warehouse business.\"}\n",
      "{\"description\":\"I ran a rapidly growing territory for the Azure cloud business for Microsoft in the South Central Region.   This included managing a team of sales professionals, cloud solution architects, and data services architects focused on strategic Azure accounts.   We were responsible for new bookings and ensuring customers are successful with their Digital Transformation initiatives.  We worked with customers and partners (ISV's, Global Alliance Partners, and National SI's) to drive Azure solution sales including Big Data (HADOOP), IAAS, PAAS, and cloud based advanced analytics solutions including machine learning, data warehousing services, Cognitive Services, and cloud based business intelligence solutions. Our team leveraged specialized overlay technical sales staff including data scientists.  Our key competitors include Amazon Web Services, IBM, Teradata, SAP, Oracle, Salesforce.com, and many others.  My team exceeded billing and consumption targets for the region while ensuring a high level of customer satisfaction in the cloud services and the Microsoft strategic partnership.  The key results from last sales year were:*  In FY 17 sales year, finished 124% attainment on Azure quota, my team drove ~ 2\\/3 of regions year over year growth in monthly Azure usage for region, region finished with #1 ranking in United States in the enterprise business for Azure usage*  I led for sales region the ISV Co-Sell initiative finishing ~ 200% of win target accelerating regional success with partners and landing key design wins to help partners accelerate scale in global market* My team won multiple new \\\"Marquee\\\" accounts for Azure working closely with strategic GSI and ISV partners, drove over 300% Azure usage growth in existing strategic accounts, and ensured customer success in Azure\"}\n",
      "{\"description\":\"Strategist for clients, including; Nike, Stella McCartney, Inflection AI, World Gold Council, Sony, aiScout, Coca-Cola, Mission44 and Illumination Entertainment.\"}\n",
      "{\"description\":\"\\u2022 Implement Data Sourcing and Management controls for HKMA regulatory reports.\\u2022 Develop and maintain data management related documentation for Business Data Elements such as data dictionaries, data lineages, trusted source assessment and data quality controls.\\u2022 Work with process owners and IT on implementation of data quality rules for End User Computing and Finance Systems.\\u2022 Gather user requirements and manage PoC development and testing of Generative AI inititives for Finance. \\u2022 Perpare business case and cost-benefit analysis for senior commitee to drive the adoption of AI solutions across Finance teams.\"}\n",
      "{\"description\":\"RSPP E CONSULENTE ESTERNO IN MATERIA DI SALUTE E SICUREZZA NEI LUOGHI DILAVORO \\u2013 SISTEMI DI GESTIONE SICUREZZA SUL LAVORO \\u2013 COORDINATORE PER LASICUREZZA NEI CANTIERI \\u2013 PROGETTAZIONE ANTINCENDIO \\u2013 VERIFICHE E PERIZIEGIURATE SU IMPIANTI DI PROTEZIONE ANTINCENDIO \\u2013 DOCUMENTI DI VALUTAZIONEDEI RISCHI - FORMAZIONE, INFORMAZIONE ED ADDESTRAMENTO DEI LAVORATORI SUIRISCHI LAVORATIVI, SULLA PREVENZIONE INCENDI E GESTIONE DELLE EMERGENZE.RSPP ESTERNO ED INTERNO \\u2013 COORDINATORE DEI LAVORI IN FASE DIPROGETTAZIONE ED ESECUZIONE \\u2013 PROGETTISTA E DIREZIONE AI LAVORI INMATERIA DI ANTINCENDIO\"}\n",
      "{\"description\":\"Currently, I am working on 4D BIM modelling and Machine Learning for Predictive Maintenance modelling for Asset Management. I have been working across various projects, notably Data Engineer secondments with two different client.\"}\n",
      "{\"description\":\"Problems in NLP, time series and ML Infra\"}\n",
      "{\"description\":\"- Prototyped an AI savings coach and OCR receipt scanner to extract data from receipts to help track the spending of Millenials and identify possible areas they can save using Azure Machine Learning, Blob Storage, OCR API, and PowerApps.- Worked closely with Microsoft, presenting solutions tailored to challenges faced by young adults and provided a live demo to a senior audit manager from RBC, showcasing unique approaches to business problems.\"}\n",
      "{\"description\":\"CS480\\/680 - Intro to Machine learning (Spring 2019, Summer 2019)\\nEvaluating project proposals, verifying python code and grading\\nexams while providing constructive and concise feedback.\"}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "jobs = pd.read_csv(\"Descriptions_and_roles_AI_flagged.csv\")\n",
    "jobs_df = pd.DataFrame(jobs)\n",
    "jobs_df_des = jobs_df[['description']]\n",
    "# Convert to JSONL (newline-delimited JSON objects)\n",
    "batch_jsonl = jobs_df_des.to_json(orient=\"records\", lines=True)\n",
    "print(batch_jsonl)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86434447-a357-47f4-9e1d-e40135fea0c8",
   "metadata": {},
   "source": [
    "## Import Libraries needed for using AWS Bedrock and Fetch API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e2c576e7-a017-4902-a1a0-a70fb73e1766",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import boto3\n",
    "import json\n",
    "import re\n",
    "from botocore.exceptions import ClientError\n",
    "\n",
    "AWS_API = os.getenv('AWS_BEARER_TOKEN_BEDROCK')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "205c2273-9a29-420a-a9fa-f5f039690870",
   "metadata": {},
   "source": [
    "## Prompts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "44fc520f-205b-4102-b789-c5354e640527",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prompts modified from Gmyrek et al, and Hosseini and Lichtinger \n",
    "\n",
    "root_prompt = \"\"\"Act as a precise classifier for LinkedIn job descriptions. Follow instructions exactly and do not add any commentary or reasoning.\"\"\"\n",
    "\n",
    "core_prompt = f\"\"\"\n",
    "You will be given 100 job descriptions in JSON format, some of which will be in different languages other than English. \n",
    "We distinguish three categories: \n",
    "A) Generative AI INTEGRATOR = descriptions of positions that build/operate LLM/Gen AI-powered systems or embed LLMs into workflows. \n",
    "B) Generative AI USER = descriptions of positions that primarily use LLM/Gen AI tools (ChatGPT, Gemini, Copilot, etc.) to perform tasks \n",
    "such as drafting, summarizing, coding assistance, customer responses without building systems. \n",
    "C) SIGNALING = descriptions of positions that vaguely mention LLMs or AI terminology without actually using or integrating it.\n",
    "\n",
    "\n",
    "NOT in-scope for integrator unless integration is explicit: \n",
    " Foundation-model pretraining/research scientist roles at model labs (OpenAI/DeepMind/etc.). \n",
    " Generic ML/NLP with no explicit LLM signals. \n",
    " Pure labeling/annotation. \n",
    "\n",
    "Edge rules: \n",
    " If both integration and user aspects appear, set role type= \"both. \n",
    " If acronyms like RAG or \"AI\" appear, assume the LLM meaning unless context contradicts. \n",
    "\n",
    "Return the results as a json array of exactly 100 strings for the AI role classification you give to each of the descriptions. \n",
    "where AI Role  \"AI INTEGRATOR\", \"AI USER\", \"BOTH\", or \"SIGNALING\". Only use the descriptions to make the classification. \n",
    "\n",
    "The array must have length 100. Do not add extra keys or commentary outside the output.\n",
    "\n",
    "Here are the job descriptions:\n",
    "\n",
    "{batch_jsonl}\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4bc4eaa-983b-4ee6-893e-7fc70705f71a",
   "metadata": {},
   "source": [
    "## Invoke the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "58088bf2-47eb-4ae0-aab8-c93b68cfb838",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make the API call to AWS GPT model.\n",
    "def description_AIrole_labeling_AWS(root_prompt, core_prompt):\n",
    "    \n",
    "    # Initialize the Bedrock Runtime client\n",
    "    client = boto3.client('bedrock-runtime', region_name = \"us-east-1\")\n",
    "    \n",
    "    # Model ID\n",
    "    model_id = 'openai.gpt-oss-120b-1:0'\n",
    "    \n",
    "    # Create the request body\n",
    "    request = {\n",
    "      \"messages\": [\n",
    "        {\"role\": \"system\", \"content\": root_prompt},\n",
    "        { \"role\": \"user\",\"content\": core_prompt}\n",
    "      ],\n",
    "      \"max_completion_tokens\": 8192,\n",
    "      \"temperature\": 0,\n",
    "      \"top_p\": 0.5,\n",
    "      #\"reasoning_effort\": \"low\",\n",
    "    }\n",
    "    \n",
    "    # Make the InvokeModel request\n",
    "    response = client.invoke_model(\n",
    "        modelId=model_id,\n",
    "        body=json.dumps(request)\n",
    "    )\n",
    "    \n",
    "    # Parse the message in the chat completion\n",
    "    response_body = json.loads(response['body'].read().decode('utf-8'))\n",
    "    response = response_body['choices'][0]['message']['content']\n",
    "    # Remove the reasoning section of the response to get just the output\n",
    "    #response = re.sub(r\"<reasoning>.*?</reasoning>\", \"\", response, flags=re.DOTALL).strip()\n",
    "    \n",
    "    return response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "1c0b3bc6-2178-4254-a342-3c94c4509359",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<reasoning>We need to classify each of the 100 descriptions into AI INTEGRATOR, AI USER, BOTH, SIGNALING. Need to output array of 100 strings.\n",
      "\n",
      "We must count 100 entries. Let's enumerate them in order given.\n",
      "\n",
      "I'll list each description with index.\n",
      "\n",
      "1: {\"description\":\"\\u2022\\tIdentify and fix over 400 disruptive transportation shipments per day... machine learning software...\"} This is about using ML software to improve shipping. No integration of LLM. It's using ML system, not LLM. It's a user of ML? It's building ML? It says \"machine learning software which calculates over 300,000 shipments per day\". They helped increase success rate. Likely they are using ML tool, not building LLM. Category: AI USER? It's generic ML, not LLM. But rule: Not integrator unless integration explicit. This is using ML software, not LLM. So AI USER? It's using ML, but not LLM. The categories are about generative AI LLM. This description doesn't mention LLM or generative AI. Might be SIGNALING? It mentions \"machine learning software\". No mention of LLM. According to categories, AI USER is about using LLM tools. This is generic ML, not LLM. So it's SIGNALING (vague mention of AI/ML without LLM). So 1 = SIGNALING.\n",
      "\n",
      "2: Digital Self-Service Launch... integrating Chat-bot technology across Thailand... strategic partnerships with Fintechs like Avatech.AI. This mentions integrating chatbot technology (likely LLM?). Could be integration of AI into workflows. So AI INTEGRATOR. Also maybe both? They integrated Chat-bot across regions. That's integration. Not just using. So AI INTEGRATOR.\n",
      "\n",
      "3: Prototyped AI Chatbot and Agents ingested with vector-embedded knowledge base and production feature store using Anthropic Claude and AWS Bedrock. That's building LLM-powered system. AI INTEGRATOR.\n",
      "\n",
      "4: Research and development of algorithms for classification... includes deep learning, object detection, etc. No LLM. So SIGNALING.\n",
      "\n",
      "5: Smart heating algorithm, smart rangehood, etc. No LLM. SIGNALING.\n",
      "\n",
      "6: Proprietary trading and software development for ML in finance and trading. No LLM. SIGNALING.\n",
      "\n",
      "7: Text mining and NLP for biomedical literature, prediction models. No LLM. SIGNALING.\n",
      "\n",
      "8: Various ML projects, sentiment analysis, etc. No LLM. SIGNALING.\n",
      "\n",
      "9: Founded North American branch of BASF stats... algorithmic trading, ML models for plants. No LLM. SIGNALING.\n",
      "\n",
      "10: Italian description about server farm, AI specialization, chatbot based on generative AI, integration with AI. They built a chatbot, integrated AI. That's AI INTEGRATOR (they integrate AI into applications). Also they mention using AI generative. So INTEGRATOR.\n",
      "\n",
      "11: Developed Deep Learning algorithm for ECG classification. No LLM. SIGNALING.\n",
      "\n",
      "12: AR project, NLP to enhance BI, etc. No LLM mention. It's using NLP, not LLM. Probably SIGNALING.\n",
      "\n",
      "13: Data cleaning for AI project, competitor analysis. No LLM. SIGNALING.\n",
      "\n",
      "14: IBM HW/SW business, Watson AI, but role is sales/partner enablement. Not building LLM. Likely SIGNALING (mentions AI but not building). Could be AI USER? They are selling AI solutions. Not using LLM. So SIGNALING.\n",
      "\n",
      "15: Leading HR services, using AI for innovation projects. No explicit LLM integration. Probably SIGNALING.\n",
      "\n",
      "16: Setting up HR Services team, using AI for innovation. Same, SIGNALING.\n",
      "\n",
      "17: Co-founded AI and data company specializing in betting exchanges, briefed devs to translate math into code. Not LLM. SIGNALING.\n",
      "\n",
      "18: Pre-sales activities, anti-money laundering system, demos regarding text processing (NLP). No LLM. SIGNALING.\n",
      "\n",
      "19: AWS services, mentions \"Gen AI Models\". Could be integration? They list Gen AI Models among services. But not explicit building. Might be SIGNALING.\n",
      "\n",
      "20: Radnet consulting, NLP to categorize email. No LLM. SIGNALING.\n",
      "\n",
      "21: Quadrical AI powered SaaS engine, hiring AI experts. This is a company building AI SaaS. Likely building AI systems (maybe LLM?). Not explicit LLM. Could be AI INTEGRATOR? It's building AI-powered SaaS engine, could involve LLM. But ambiguous. Since it's AI powered SaaS, likely integration of AI into product. I'd label AI INTEGRATOR.\n",
      "\n",
      "22: Federated machine learning in drug discovery. No LLM. SIGNALING.\n",
      "\n",
      "23: Develop ML solutions on GCP. No LLM. SIGNALING.\n",
      "\n",
      "24: Use ML to boost trading algorithm. No LLM. SIGNALING.\n",
      "\n",
      "25: Analyst, developer, consultant, credit risk models, CV for self-driven car. No LLM. SIGNALING.\n",
      "\n",
      "26: Creative AI Division coordinator, AI camp, AI study course, AI and blockchain. Likely SIGNALING (coordination, not building LLM).\n",
      "\n",
      "27: Dealer task, ML quantitative investment decision support, dashboards. No LLM. SIGNALING.\n",
      "\n",
      "28: Data Management, Data Mining, Big Data, ML/AI. Vague. SIGNALING.\n",
      "\n",
      "29: R&D intelligent machine, vision, etc. No LLM. SIGNALING.\n",
      "\n",
      "30: AI scientist and user experience lead. Could be both? Title suggests both scientist (building) and UX lead (using). No details. Likely SIGNALING.\n",
      "\n",
      "31: Demand forecasting, statistical modeling, no LLM. SIGNALING.\n",
      "\n",
      "32: Built AI-powered smartphone app for art enthusiasts. Likely AI INTEGRATOR (built app with AI). Could be using generative AI? Not explicit LLM. But AI-powered app maybe includes image recognition. Not LLM. Might be SIGNALING. Since not LLM. I'll choose SIGNALING.\n",
      "\n",
      "33: Human-machine interfaces, unsupervised recognition, various ML. No LLM. SIGNALING.\n",
      "\n",
      "34: Sentiment analysis etc. Arabic dialect. No LLM. SIGNALING.\n",
      "\n",
      "35: Supervised/unsupervised ML models, stock prediction, Covid storyboard. No LLM. SIGNALING.\n",
      "\n",
      "36: Writing blogs about AI, ML, DL. No LLM. SIGNALING.\n",
      "\n",
      "37: Amazon pricing strategy, large scale ML. No LLM. SIGNALING.\n",
      "\n",
      "38: French description about social selling, GDPR, email campaigns, LinkedIn Sales Navigator. No LLM. SIGNALING.\n",
      "\n",
      "39: Business Developer in SAP Innovation Center Machine Learning team. No LLM. SIGNALING.\n",
      "\n",
      "40: Work stream leadership for transition (ML) activities. No LLM. SIGNALING.\n",
      "\n",
      "41: Propose solutions, deliver POCs, demos, AI. Could be integrator? They deliver POCs and demos, maybe building AI solutions. Likely AI INTEGRATOR (delivering AI solutions). But could be user. Since they propose AI solutions, likely building prototypes. I'll label AI INTEGRATOR.\n",
      "\n",
      "42: Worked on predictive modelling using statistical techniques and ML tools. No LLM. SIGNALING.\n",
      "\n",
      "43: Stress biomarkers, ML pipelines for physiological signals. No LLM. SIGNALING.\n",
      "\n",
      "44: Product Owner of Photovoltaic Products, defining neural network research areas. Not LLM. SIGNALING.\n",
      "\n",
      "45: Portuguese description of deep learning method combining visual and textual representations. No LLM. SIGNALING.\n",
      "\n",
      "46: ChatGPT as director at educational academy... mentions ChatGPT? Actually description says \"ChatGPTAs a director...\" maybe they used ChatGPT? It says \"ChatGPTAs a director...\" ambiguous. It seems they used digital technology, not necessarily LLM. Might be AI USER (using ChatGPT). But description doesn't mention using ChatGPT for tasks, just digital tech. Could be SIGNALING. I'll choose SIGNALING.\n",
      "\n",
      "47: Capgemini ETL work, no AI. SIGNALING.\n",
      "\n",
      "48: Cientra company description includes AI, ML, BOTS, Voice, Image Recognition. It's a services company. Not specific role. Likely SIGNALING.\n",
      "\n",
      "49: Engineering leadership of 175 engineers, automotive etc. No AI. SIGNALING.\n",
      "\n",
      "50: Cloud solutions architect, mentions AI Integration in Cloud Workflows, ML deployment. This role includes integration of AI into cloud workflows. Likely AI INTEGRATOR (they integrate AI). Could also be BOTH? They also design AI automation. Probably INTEGRATOR.\n",
      "\n",
      "51: RPO design, AI chatbot automation. This is using AI tools for recruitment automation. That's AI USER (using AI chatbot). Not building LLM. So AI USER.\n",
      "\n",
      "52: Talent acquisition, implemented Watson Recruiter AI tools. Using AI tools. AI USER.\n",
      "\n",
      "53: Designing data collection workflow and training ML model for gait analysis. No LLM. SIGNALING.\n",
      "\n",
      "54: Research on AI-based MRI analysis. No LLM. SIGNALING.\n",
      "\n",
      "55: Sales Manager for strategic outsourcer accounts. No AI. SIGNALING.\n",
      "\n",
      "56: Built multiclass CNN tax document classifier, OCR, Azure Computer Vision. No LLM. SIGNALING.\n",
      "\n",
      "57: Causal inference pipeline for blood glucose. No LLM. SIGNALING.\n",
      "\n",
      "58: Thomson Reuters Labs ML infra. No LLM. SIGNALING.\n",
      "\n",
      "59: AI drug discovery, ML for healthcare. No LLM. SIGNALING.\n",
      "\n",
      "60: Research on numerical methods, eigensolvers, deep learning. No LLM. SIGNALING.\n",
      "\n",
      "61: Process Lead with Capgemini Business Services, SAP FICO. No AI. SIGNALING.\n",
      "\n",
      "62: Testing of large machines, torque measurement. No AI. SIGNALING.\n",
      "\n",
      "63: Business Analyst Salesforce, introduced Marketing AI review processes. Using AI for marketing. AI USER (uses AI). Not building LLM.\n",
      "\n",
      "64: Skills Funding Agency portal, RAG rating (RAG maybe Retrieval Augmented Generation). They mention RAG rating. Could be LLM? RAG is Retrieval Augmented Generation, which is LLM technique. They facilitated users with RAG rating. Might be AI USER? They support RAG rating, maybe using LLM. Could be SIGNALING. Since ambiguous, but RAG suggests LLM. However they are not building, just supporting. So AI USER.\n",
      "\n",
      "65: Chief Architect, leads AI and ML initiatives, but also cyber security. Role includes leading AI initiatives, likely integrator? He leads AI projects, maybe building. Could be BOTH? He is leading AI/ML, but not specific LLM. Probably SIGNALING.\n",
      "\n",
      "66: Program Manager at Algolia, integrated AI team to R&D. That's integration of AI team. AI INTEGRATOR.\n",
      "\n",
      "67: Law school teaching, no AI. SIGNALING.\n",
      "\n",
      "68: Consulting on AI potential, governance, biosecurity. Likely AI USER? They advise on AI, not building. Could be SIGNALING. Probably SIGNALING.\n",
      "\n",
      "69: Consulting on M&A, transformation, AI/ML, RPA. Likely SIGNALING.\n",
      "\n",
      "70: Turkish description of supply chain, no AI. SIGNALING.\n",
      "\n",
      "71: Research internship testing ML pipelines, AutoML. No LLM. SIGNALING.\n",
      "\n",
      "72: French description about employment service, no AI. SIGNALING.\n",
      "\n",
      "73: Decision maker, ML models across domains. No LLM. SIGNALING.\n",
      "\n",
      "74: Research stay generating synthetic ultrasound data, training ML segmentation. No LLM. SIGNALING.\n",
      "\n",
      "75: Interset security analytics using unsupervised ML. No LLM. SIGNALING.\n",
      "\n",
      "76: Head of Agile Coaching Practice, includes Machine Learning CoP. Not building LLM. SIGNALING.\n",
      "\n",
      "77: Microsoft solution suites, includes AI. Role is sales/technical? Not building LLM. SIGNALING.\n",
      "\n",
      "78: Oil & gas ML applications. No LLM. SIGNALING.\n",
      "\n",
      "79: Same as 78 duplicate. SIGNALING.\n",
      "\n",
      "80: Developed automatic solutions for inventory control, ML. No LLM. SIGNALING.\n",
      "\n",
      "81: Horticulture consulting, no AI. SIGNALING.\n",
      "\n",
      "82: Python APIs Flask, ML classification. No LLM. SIGNALING.\n",
      "\n",
      "83: Course list, includes AI, ML. Not a role. SIGNALING.\n",
      "\n",
      "84: Wing company description includes AI/Big Data etc. Not role. SIGNALING.\n",
      "\n",
      "85: Electrical installation job. No AI. SIGNALING.\n",
      "\n",
      "86: Fast fashion profitability using ML, feature analysis. No LLM. SIGNALING.\n",
      "\n",
      "87: French project MSP for EDF, no AI. SIGNALING.\n",
      "\n",
      "88: Audit compliance RGPD, data. No AI. SIGNALING.\n",
      "\n",
      "89: Group Innovation Architecture & AI-Technology. No role specifics. SIGNALING.\n",
      "\n",
      "90: Transformed Business Development, AI co-leads, but role is business development. Might be AI USER? They integrate AI into business development. Could be SIGNALING.\n",
      "\n",
      "91: ThoughtSpot AI-driven analytics platform, sales role. Using AI platform. AI USER.\n",
      "\n",
      "92: Microsoft data platform sales, includes AI, data scientists. AI USER (selling AI solutions).\n",
      "\n",
      "93: Azure cloud sales, includes AI services. AI USER.\n",
      "\n",
      "94: Strategist for clients including Inflection AI etc. Likely AI USER (consulting). SIGNALING? They work with AI companies. Probably SIGNALING.\n",
      "\n",
      "95: HKMA regulatory reports, PoC development of Generative AI initiatives. That's AI INTEGRATOR (building PoC). Could be BOTH? They develop PoC, manage data. Likely INTEGRATOR.\n",
      "\n",
      "96: Italian health and safety coordinator. No AI. SIGNALING.\n",
      "\n",
      "97: 4D BIM modelling and ML for predictive maintenance. No LLM. SIGNALING.\n",
      "\n",
      "98: Problems in NLP, time series and ML Infra. No LLM. SIGNALING.\n",
      "\n",
      "99: AI savings coach and OCR receipt scanner using Azure ML, PowerApps. Building AI solution. AI INTEGRATOR.\n",
      "\n",
      "100: CS480/680 intro to ML teaching, grading. No LLM. SIGNALING.\n",
      "\n",
      "Now we have to ensure 100 entries. Let's count indices.\n",
      "\n",
      "I'll list with classification:\n",
      "\n",
      "1 SIGNALING\n",
      "2 AI INTEGRATOR\n",
      "3 AI INTEGRATOR\n",
      "4 SIGNALING\n",
      "5 SIGNALING\n",
      "6 SIGNALING\n",
      "7 SIGNALING\n",
      "8 SIGNALING\n",
      "9 SIGNALING\n",
      "10 AI INTEGRATOR\n",
      "11 SIGNALING\n",
      "12 SIGNALING\n",
      "13 SIGNALING\n",
      "14 SIGNALING\n",
      "15 SIGNALING\n",
      "16 SIGNALING\n",
      "17 SIGNALING\n",
      "18 SIGNALING\n",
      "19 SIGNALING\n",
      "20 SIGNALING\n",
      "21 AI INTEGRATOR\n",
      "22 SIGNALING\n",
      "23 SIGNALING\n",
      "24 SIGNALING\n",
      "25 SIGNALING\n",
      "26 SIGNALING\n",
      "27 SIGNALING\n",
      "28 SIGNALING\n",
      "29 SIGNALING\n",
      "30 SIGNALING\n",
      "31 SIGNALING\n",
      "32 SIGNALING\n",
      "33 SIGNALING\n",
      "34 SIGNALING\n",
      "35 SIGNALING\n",
      "36 SIGNALING\n",
      "37 SIGNALING\n",
      "38 SIGNALING\n",
      "39 SIGNALING\n",
      "40 SIGNALING\n",
      "41 AI INTEGRATOR\n",
      "42 SIGNALING\n",
      "43 SIGNALING\n",
      "44 SIGNALING\n",
      "45 SIGNALING\n",
      "46 SIGNALING\n",
      "47 SIGNALING\n",
      "48 SIGNALING\n",
      "49 SIGNALING\n",
      "50 AI INTEGRATOR\n",
      "51 AI USER\n",
      "52 AI USER\n",
      "53 SIGNALING\n",
      "54 SIGNALING\n",
      "55 SIGNALING\n",
      "56 SIGNALING\n",
      "57 SIGNALING\n",
      "58 SIGNALING\n",
      "59 SIGNALING\n",
      "60 SIGNALING\n",
      "61 SIGNALING\n",
      "62 SIGNALING\n",
      "63 AI USER\n",
      "64 AI USER\n",
      "65 SIGNALING\n",
      "66 AI INTEGRATOR\n",
      "67 SIGNALING\n",
      "68 SIGNALING\n",
      "69 SIGNALING\n",
      "70 SIGNALING\n",
      "71 SIGNALING\n",
      "72 SIGNALING\n",
      "73 SIGNALING\n",
      "74 SIGNALING\n",
      "75 SIGNALING\n",
      "76 SIGNALING\n",
      "77 SIGNALING\n",
      "78 SIGNALING\n",
      "79 SIGNALING\n",
      "80 SIGNALING\n",
      "81 SIGNALING\n",
      "82 SIGNALING\n",
      "83 SIGNALING\n",
      "84 SIGNALING\n",
      "85 SIGNALING\n",
      "86 SIGNALING\n",
      "87 SIGNALING\n",
      "88 SIGNALING\n",
      "89 SIGNALING\n",
      "90 SIGNALING\n",
      "91 AI USER\n",
      "92 AI USER\n",
      "93 AI USER\n",
      "94 SIGNALING\n",
      "95 AI INTEGRATOR\n",
      "96 SIGNALING\n",
      "97 SIGNALING\n",
      "98 SIGNALING\n",
      "99 AI INTEGRATOR\n",
      "100 SIGNALING\n",
      "\n",
      "Now ensure count 100. Let's count again quickly: I have 100 entries.\n",
      "\n",
      "Now produce JSON array of strings exactly.\n",
      "\n",
      "The strings must be exactly \"AI INTEGRATOR\", \"AI USER\", \"BOTH\", or \"SIGNALING\". No extra spaces.\n",
      "\n",
      "Let's output array.\n",
      "\n",
      "</reasoning>[\"SIGNALING\",\"AI INTEGRATOR\",\"AI INTEGRATOR\",\"SIGNALING\",\"SIGNALING\",\"SIGNALING\",\"SIGNALING\",\"SIGNALING\",\"SIGNALING\",\"AI INTEGRATOR\",\"SIGNALING\",\"SIGNALING\",\"SIGNALING\",\"SIGNALING\",\"SIGNALING\",\"SIGNALING\",\"SIGNALING\",\"SIGNALING\",\"SIGNALING\",\"SIGNALING\",\"AI INTEGRATOR\",\"SIGNALING\",\"SIGNALING\",\"SIGNALING\",\"SIGNALING\",\"SIGNALING\",\"SIGNALING\",\"SIGNALING\",\"SIGNALING\",\"SIGNALING\",\"SIGNALING\",\"SIGNALING\",\"SIGNALING\",\"SIGNALING\",\"SIGNALING\",\"SIGNALING\",\"SIGNALING\",\"SIGNALING\",\"SIGNALING\",\"SIGNALING\",\"AI INTEGRATOR\",\"SIGNALING\",\"SIGNALING\",\"SIGNALING\",\"SIGNALING\",\"SIGNALING\",\"SIGNALING\",\"SIGNALING\",\"SIGNALING\",\"AI INTEGRATOR\",\"AI USER\",\"AI USER\",\"SIGNALING\",\"SIGNALING\",\"SIGNALING\",\"SIGNALING\",\"SIGNALING\",\"SIGNALING\",\"SIGNALING\",\"SIGNALING\",\"SIGNALING\",\"SIGNALING\",\"SIGNALING\",\"SIGNALING\",\"AI USER\",\"AI USER\",\"SIGNALING\",\"AI INTEGRATOR\",\"SIGNALING\",\"SIGNALING\",\"SIGNALING\",\"SIGNALING\",\"SIGNALING\",\"SIGNALING\",\"SIGNALING\",\"SIGNALING\",\"SIGNALING\",\"SIGNALING\",\"SIGNALING\",\"SIGNALING\",\"SIGNALING\",\"SIGNALING\",\"SIGNALING\",\"SIGNALING\",\"SIGNALING\",\"SIGNALING\",\"SIGNALING\",\"SIGNALING\",\"SIGNALING\",\"SIGNALING\",\"AI USER\",\"AI USER\",\"AI USER\",\"SIGNALING\",\"AI INTEGRATOR\",\"SIGNALING\",\"SIGNALING\",\"SIGNALING\",\"AI INTEGRATOR\",\"SIGNALING\"]\n"
     ]
    }
   ],
   "source": [
    "# Print the response\n",
    "result = description_AIrole_labeling_AWS(root_prompt, core_prompt)\n",
    "print(result)\n",
    "roles = result.split(\",\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "040b4bc1-f9a7-409f-8a7d-760675cd6961",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clean response to remove the reasoning and just show output\n",
    "response = re.sub(r\"<reasoning>.*?</reasoning>\", \"\", result, flags=re.DOTALL).strip()\n",
    "roles = json.loads(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "337860a2-c138-44f1-acbc-3be0870753ec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>AI_role</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>SIGNALING</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>AI INTEGRATOR</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>AI INTEGRATOR</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>SIGNALING</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>SIGNALING</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>SIGNALING</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>SIGNALING</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>SIGNALING</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>AI INTEGRATOR</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>SIGNALING</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows  1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          AI_role\n",
       "0       SIGNALING\n",
       "1   AI INTEGRATOR\n",
       "2   AI INTEGRATOR\n",
       "3       SIGNALING\n",
       "4       SIGNALING\n",
       "..            ...\n",
       "95      SIGNALING\n",
       "96      SIGNALING\n",
       "97      SIGNALING\n",
       "98  AI INTEGRATOR\n",
       "99      SIGNALING\n",
       "\n",
       "[100 rows x 1 columns]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a data frame from the output\n",
    "import pandas as pd\n",
    "AI_roles_df = pd.DataFrame(roles, columns = ['AI_role'])\n",
    "AI_roles_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "5005fd26-9f09-4887-8bc1-40074d75c3d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Join output df with original\n",
    "jobs_AI_role = jobs_df.join(AI_roles_df)\n",
    "# Save to a csv file\n",
    "jobs_AI_role.to_csv(\"jobs_AI_role.csv\", index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "73847488-0242-432d-b9cb-a873d36a7e1f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['SIGNALING',\n",
       "  'AI INTEGRATOR',\n",
       "  'AI INTEGRATOR',\n",
       "  'SIGNALING',\n",
       "  'SIGNALING',\n",
       "  'SIGNALING',\n",
       "  'SIGNALING',\n",
       "  'SIGNALING',\n",
       "  'SIGNALING',\n",
       "  'AI INTEGRATOR',\n",
       "  'SIGNALING',\n",
       "  'AI USER',\n",
       "  'SIGNALING',\n",
       "  'SIGNALING',\n",
       "  'AI USER',\n",
       "  'AI USER',\n",
       "  'AI INTEGRATOR',\n",
       "  'SIGNALING',\n",
       "  'AI USER',\n",
       "  'AI USER',\n",
       "  'SIGNALING',\n",
       "  'SIGNALING',\n",
       "  'SIGNALING',\n",
       "  'SIGNALING',\n",
       "  'SIGNALING',\n",
       "  'SIGNALING',\n",
       "  'SIGNALING',\n",
       "  'SIGNALING',\n",
       "  'SIGNALING',\n",
       "  'SIGNALING',\n",
       "  'SIGNALING',\n",
       "  'AI INTEGRATOR',\n",
       "  'SIGNALING',\n",
       "  'SIGNALING',\n",
       "  'SIGNALING',\n",
       "  'SIGNALING',\n",
       "  'SIGNALING',\n",
       "  'SIGNALING',\n",
       "  'SIGNALING',\n",
       "  'SIGNALING',\n",
       "  'AI USER',\n",
       "  'SIGNALING',\n",
       "  'SIGNALING',\n",
       "  'SIGNALING',\n",
       "  'SIGNALING',\n",
       "  'AI USER',\n",
       "  'SIGNALING',\n",
       "  'SIGNALING',\n",
       "  'SIGNALING',\n",
       "  'BOTH',\n",
       "  'AI INTEGRATOR',\n",
       "  'AI USER',\n",
       "  'AI INTEGRATOR',\n",
       "  'AI INTEGRATOR',\n",
       "  'SIGNALING',\n",
       "  'AI INTEGRATOR',\n",
       "  'SIGNALING',\n",
       "  'SIGNALING',\n",
       "  'SIGNALING',\n",
       "  'SIGNALING',\n",
       "  'SIGNALING',\n",
       "  'SIGNALING',\n",
       "  'AI USER',\n",
       "  'SIGNALING',\n",
       "  'AI USER',\n",
       "  'BOTH',\n",
       "  'SIGNALING',\n",
       "  'AI USER',\n",
       "  'AI USER',\n",
       "  'SIGNALING',\n",
       "  'SIGNALING',\n",
       "  'SIGNALING',\n",
       "  'SIGNALING',\n",
       "  'SIGNALING',\n",
       "  'SIGNALING',\n",
       "  'SIGNALING',\n",
       "  'SIGNALING',\n",
       "  'SIGNALING',\n",
       "  'SIGNALING',\n",
       "  'SIGNALING',\n",
       "  'SIGNALING',\n",
       "  'SIGNALING',\n",
       "  'SIGNALING',\n",
       "  'SIGNALING',\n",
       "  'AI INTEGRATOR',\n",
       "  'SIGNALING',\n",
       "  'SIGNALING',\n",
       "  'SIGNALING',\n",
       "  'AI USER',\n",
       "  'AI USER',\n",
       "  'AI USER',\n",
       "  'AI USER',\n",
       "  'AI USER',\n",
       "  'AI INTEGRATOR',\n",
       "  'SIGNALING',\n",
       "  'AI INTEGRATOR',\n",
       "  'SIGNALING',\n",
       "  'AI INTEGRATOR',\n",
       "  'SIGNALING']]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Add the output roles to a list\n",
    "AI_roles = []\n",
    "AI_roles.append(roles)\n",
    "AI_roles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "f22d61fc-21d2-471e-b7e0-01344b3c74a3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['SIGNALING',\n",
       " 'AI INTEGRATOR',\n",
       " 'AI INTEGRATOR',\n",
       " 'SIGNALING',\n",
       " 'SIGNALING',\n",
       " 'SIGNALING',\n",
       " 'SIGNALING',\n",
       " 'SIGNALING',\n",
       " 'SIGNALING',\n",
       " 'AI INTEGRATOR',\n",
       " 'SIGNALING',\n",
       " 'AI USER',\n",
       " 'SIGNALING',\n",
       " 'SIGNALING',\n",
       " 'AI USER',\n",
       " 'AI USER',\n",
       " 'AI INTEGRATOR',\n",
       " 'SIGNALING',\n",
       " 'AI USER',\n",
       " 'AI USER',\n",
       " 'SIGNALING',\n",
       " 'SIGNALING',\n",
       " 'SIGNALING',\n",
       " 'SIGNALING',\n",
       " 'SIGNALING',\n",
       " 'SIGNALING',\n",
       " 'SIGNALING',\n",
       " 'SIGNALING',\n",
       " 'SIGNALING',\n",
       " 'SIGNALING',\n",
       " 'SIGNALING',\n",
       " 'AI INTEGRATOR',\n",
       " 'SIGNALING',\n",
       " 'SIGNALING',\n",
       " 'SIGNALING',\n",
       " 'SIGNALING',\n",
       " 'SIGNALING',\n",
       " 'SIGNALING',\n",
       " 'SIGNALING',\n",
       " 'SIGNALING',\n",
       " 'AI USER',\n",
       " 'SIGNALING',\n",
       " 'SIGNALING',\n",
       " 'SIGNALING',\n",
       " 'SIGNALING',\n",
       " 'AI USER',\n",
       " 'SIGNALING',\n",
       " 'SIGNALING',\n",
       " 'SIGNALING',\n",
       " 'BOTH',\n",
       " 'AI INTEGRATOR',\n",
       " 'AI USER',\n",
       " 'AI INTEGRATOR',\n",
       " 'AI INTEGRATOR',\n",
       " 'SIGNALING',\n",
       " 'AI INTEGRATOR',\n",
       " 'SIGNALING',\n",
       " 'SIGNALING',\n",
       " 'SIGNALING',\n",
       " 'SIGNALING',\n",
       " 'SIGNALING',\n",
       " 'SIGNALING',\n",
       " 'AI USER',\n",
       " 'SIGNALING',\n",
       " 'AI USER',\n",
       " 'BOTH',\n",
       " 'SIGNALING',\n",
       " 'AI USER',\n",
       " 'AI USER',\n",
       " 'SIGNALING',\n",
       " 'SIGNALING',\n",
       " 'SIGNALING',\n",
       " 'SIGNALING',\n",
       " 'SIGNALING',\n",
       " 'SIGNALING',\n",
       " 'SIGNALING',\n",
       " 'SIGNALING',\n",
       " 'SIGNALING',\n",
       " 'SIGNALING',\n",
       " 'SIGNALING',\n",
       " 'SIGNALING',\n",
       " 'SIGNALING',\n",
       " 'SIGNALING',\n",
       " 'SIGNALING',\n",
       " 'AI INTEGRATOR',\n",
       " 'SIGNALING',\n",
       " 'SIGNALING',\n",
       " 'SIGNALING',\n",
       " 'AI USER',\n",
       " 'AI USER',\n",
       " 'AI USER',\n",
       " 'AI USER',\n",
       " 'AI USER',\n",
       " 'AI INTEGRATOR',\n",
       " 'SIGNALING',\n",
       " 'AI INTEGRATOR',\n",
       " 'SIGNALING',\n",
       " 'AI INTEGRATOR',\n",
       " 'SIGNALING']"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Flatten out the list\n",
    "from itertools import chain\n",
    "AI_roles = list(chain.from_iterable(AI_roles))\n",
    "AI_roles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "88f48877-4802-4131-b68a-6d83239b7622",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'SIGNALING'"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#AI_roles[-1] = AI_roles[-1].replace(')', '')\n",
    "AI_roles[59]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "c5b48b8b-7dfd-4671-91f9-aae611bb3fac",
   "metadata": {},
   "outputs": [],
   "source": [
    "AI_roles_array = np.array(AI_roles).reshape((len(AI_roles) ,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "e237b7aa-b523-4a4b-a54c-ba24a2b8a884",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(104, 1)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "AI_roles_array.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "e1808dee-65a4-4bd2-a02a-825234189499",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "1 columns passed, passed data had 110 columns",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\core\\internals\\construction.py:939\u001b[0m, in \u001b[0;36m_finalize_columns_and_data\u001b[1;34m(content, columns, dtype)\u001b[0m\n\u001b[0;32m    938\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 939\u001b[0m     columns \u001b[38;5;241m=\u001b[39m _validate_or_indexify_columns(contents, columns)\n\u001b[0;32m    940\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mAssertionError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[0;32m    941\u001b[0m     \u001b[38;5;66;03m# GH#26429 do not raise user-facing AssertionError\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\core\\internals\\construction.py:986\u001b[0m, in \u001b[0;36m_validate_or_indexify_columns\u001b[1;34m(content, columns)\u001b[0m\n\u001b[0;32m    984\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_mi_list \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(columns) \u001b[38;5;241m!=\u001b[39m \u001b[38;5;28mlen\u001b[39m(content):  \u001b[38;5;66;03m# pragma: no cover\u001b[39;00m\n\u001b[0;32m    985\u001b[0m     \u001b[38;5;66;03m# caller's responsibility to check for this...\u001b[39;00m\n\u001b[1;32m--> 986\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAssertionError\u001b[39;00m(\n\u001b[0;32m    987\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(columns)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m columns passed, passed data had \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    988\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(content)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m columns\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    989\u001b[0m     )\n\u001b[0;32m    990\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_mi_list:\n\u001b[0;32m    991\u001b[0m     \u001b[38;5;66;03m# check if nested list column, length of each sub-list should be equal\u001b[39;00m\n",
      "\u001b[1;31mAssertionError\u001b[0m: 1 columns passed, passed data had 110 columns",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[21], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m roles \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mDataFrame(data \u001b[38;5;241m=\u001b[39m AI_roles, columns \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mAI_roles\u001b[39m\u001b[38;5;124m'\u001b[39m: np\u001b[38;5;241m.\u001b[39marange(\u001b[38;5;28mlen\u001b[39m(AI_roles))})\n\u001b[0;32m      2\u001b[0m roles\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\core\\frame.py:851\u001b[0m, in \u001b[0;36mDataFrame.__init__\u001b[1;34m(self, data, index, columns, dtype, copy)\u001b[0m\n\u001b[0;32m    849\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m columns \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    850\u001b[0m         columns \u001b[38;5;241m=\u001b[39m ensure_index(columns)\n\u001b[1;32m--> 851\u001b[0m     arrays, columns, index \u001b[38;5;241m=\u001b[39m nested_data_to_arrays(\n\u001b[0;32m    852\u001b[0m         \u001b[38;5;66;03m# error: Argument 3 to \"nested_data_to_arrays\" has incompatible\u001b[39;00m\n\u001b[0;32m    853\u001b[0m         \u001b[38;5;66;03m# type \"Optional[Collection[Any]]\"; expected \"Optional[Index]\"\u001b[39;00m\n\u001b[0;32m    854\u001b[0m         data,\n\u001b[0;32m    855\u001b[0m         columns,\n\u001b[0;32m    856\u001b[0m         index,  \u001b[38;5;66;03m# type: ignore[arg-type]\u001b[39;00m\n\u001b[0;32m    857\u001b[0m         dtype,\n\u001b[0;32m    858\u001b[0m     )\n\u001b[0;32m    859\u001b[0m     mgr \u001b[38;5;241m=\u001b[39m arrays_to_mgr(\n\u001b[0;32m    860\u001b[0m         arrays,\n\u001b[0;32m    861\u001b[0m         columns,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    864\u001b[0m         typ\u001b[38;5;241m=\u001b[39mmanager,\n\u001b[0;32m    865\u001b[0m     )\n\u001b[0;32m    866\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\core\\internals\\construction.py:520\u001b[0m, in \u001b[0;36mnested_data_to_arrays\u001b[1;34m(data, columns, index, dtype)\u001b[0m\n\u001b[0;32m    517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_named_tuple(data[\u001b[38;5;241m0\u001b[39m]) \u001b[38;5;129;01mand\u001b[39;00m columns \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    518\u001b[0m     columns \u001b[38;5;241m=\u001b[39m ensure_index(data[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39m_fields)\n\u001b[1;32m--> 520\u001b[0m arrays, columns \u001b[38;5;241m=\u001b[39m to_arrays(data, columns, dtype\u001b[38;5;241m=\u001b[39mdtype)\n\u001b[0;32m    521\u001b[0m columns \u001b[38;5;241m=\u001b[39m ensure_index(columns)\n\u001b[0;32m    523\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m index \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\core\\internals\\construction.py:845\u001b[0m, in \u001b[0;36mto_arrays\u001b[1;34m(data, columns, dtype)\u001b[0m\n\u001b[0;32m    842\u001b[0m     data \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28mtuple\u001b[39m(x) \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m data]\n\u001b[0;32m    843\u001b[0m     arr \u001b[38;5;241m=\u001b[39m _list_to_arrays(data)\n\u001b[1;32m--> 845\u001b[0m content, columns \u001b[38;5;241m=\u001b[39m _finalize_columns_and_data(arr, columns, dtype)\n\u001b[0;32m    846\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m content, columns\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\core\\internals\\construction.py:942\u001b[0m, in \u001b[0;36m_finalize_columns_and_data\u001b[1;34m(content, columns, dtype)\u001b[0m\n\u001b[0;32m    939\u001b[0m     columns \u001b[38;5;241m=\u001b[39m _validate_or_indexify_columns(contents, columns)\n\u001b[0;32m    940\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mAssertionError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[0;32m    941\u001b[0m     \u001b[38;5;66;03m# GH#26429 do not raise user-facing AssertionError\u001b[39;00m\n\u001b[1;32m--> 942\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(err) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01merr\u001b[39;00m\n\u001b[0;32m    944\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(contents) \u001b[38;5;129;01mand\u001b[39;00m contents[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mdtype \u001b[38;5;241m==\u001b[39m np\u001b[38;5;241m.\u001b[39mobject_:\n\u001b[0;32m    945\u001b[0m     contents \u001b[38;5;241m=\u001b[39m convert_object_array(contents, dtype\u001b[38;5;241m=\u001b[39mdtype)\n",
      "\u001b[1;31mValueError\u001b[0m: 1 columns passed, passed data had 110 columns"
     ]
    }
   ],
   "source": [
    "roles = pd.DataFrame(data = AI_roles, columns = {'AI_roles': np.arange(len(AI_roles))})\n",
    "roles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5acce2d6-dc45-4326-a299-a0685a477719",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
